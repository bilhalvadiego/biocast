{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyshorteners\n",
    "\n",
    "s = pyshorteners.Shortener()\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from insta28 import *\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')\n",
    "load_dotenv('paramns.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter a data e hora atuais\n",
    "data_hora_atual = datetime.datetime.now()\n",
    "\n",
    "# Formatar a data e hora\n",
    "data_hora_formatada = data_hora_atual.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "timestampNow = int(data_hora_atual.timestamp() * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classImg(\n",
    "    hydraAPIURL: str\n",
    "    , hydraAPIHost: str\n",
    "    , rapidAPIKey: str\n",
    "    , imgURL: str    \n",
    "):\n",
    "    try:\n",
    "        payload = { \"image\": imgURL}\n",
    "        headers = {\n",
    "            \"content-type\": \"application/json\"\n",
    "            ,\"X-RapidAPI-Key\": rapidAPIKey\n",
    "            ,\"X-RapidAPI-Host\": hydraAPIHost\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(hydraAPIURL, json=payload, headers=headers)\n",
    "        except Exception as e:\n",
    "            return False, e, None\n",
    "\n",
    "        dictHydra = response.json()\n",
    "        \n",
    "        if (dictHydra['statusCode'] == 200):\n",
    "            return True, dictHydra['body']['image_classification'], dictHydra['body']['object_detection']\n",
    "        else:\n",
    "            return False, None, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        if len(dictHydra):\n",
    "            return False, e, dictHydra\n",
    "        else:\n",
    "            return False, e, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = os.getenv('INSTA28URL')\n",
    "\n",
    "queryHashTag = input(\"Qual o termo que você quer pesquisar?\")\n",
    "querystring = {\"hash_tag\":queryHashTag}\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": os.getenv('RAPIDAPI'),\n",
    "\t\"X-RapidAPI-Host\": os.getenv(\"INSTA28HOST\")\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "dictInsta = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = Instmages(dictInsta['data'], dictInsta['extensions'], dictInsta['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashs = Hashtag(\n",
    "    inst.data['hashtag']['id']\n",
    "    , inst.data['hashtag']['name']\n",
    "    , inst.data['hashtag']['allow_following']\n",
    "    , inst.data['hashtag']['is_following']\n",
    "    , inst.data['hashtag']['is_top_media_only']\n",
    "    , inst.data['hashtag']['profile_pic_url']\n",
    "    , inst.data['hashtag']['edge_hashtag_to_media']\n",
    "    , inst.data['hashtag']['edge_hashtag_to_content_advisory']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = EdgeHashtagToMedia(\n",
    "    count = hashs.edge_hashtag_to_media['count']\n",
    "    ,page_info=hashs.edge_hashtag_to_media['page_info']\n",
    "    ,edges= hashs.edge_hashtag_to_media['edges']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "dictResult = {}\n",
    "\n",
    "dictResult['hashtag'] = queryHashTag\n",
    "dictResult['datetime'] = data_hora_formatada\n",
    "dictResult['timestampnow'] = timestampNow\n",
    "\n",
    "lstPrplNode = []\n",
    "for edge in edges.edges:\n",
    "    node = EdgeHashtagToMediaEdge(\n",
    "        node = edge['node']\n",
    "    )\n",
    "    prplNode = PurpleNode(\n",
    "        comments_disabled = node.node['comments_disabled']\n",
    "        ,typename = node.node['__typename']\n",
    "        ,id = node.node['id']\n",
    "        ,edge_media_to_caption = node.node['edge_media_to_caption']\n",
    "        ,shortcode = node.node['shortcode']\n",
    "        ,edge_media_to_comment = node.node['edge_media_to_comment']\n",
    "        ,taken_at_timestamp = node.node['taken_at_timestamp']\n",
    "        ,dimensions = node.node['dimensions']\n",
    "        ,display_url = node.node['display_url']\n",
    "        ,edge_liked_by = node.node['edge_liked_by']\n",
    "        ,edge_media_preview_like = node.node['edge_media_preview_like']\n",
    "        ,owner = node.node['owner']\n",
    "        ,thumbnail_src = node.node['thumbnail_src']\n",
    "        ,thumbnail_resources = node.node['thumbnail_resources']\n",
    "        ,is_video = node.node['is_video']\n",
    "        ,accessibility_caption = node.node['accessibility_caption']\n",
    "    )\n",
    "    \n",
    "    if prplNode.is_video:\n",
    "        continue\n",
    "    \n",
    "    for caption in prplNode.edge_media_to_caption['edges']:\n",
    "        node = EdgeMediaToCaptionEdge(\n",
    "            node = caption['node']\n",
    "        )\n",
    "        \n",
    "        fluffyText = FluffyNode(text = node.node['text'])\n",
    "        _shortUrl = s.isgd.short(prplNode.display_url)\n",
    "        \n",
    "        status, imgClass, objDtct = classImg(\n",
    "            hydraAPIURL = os.getenv(\"HYDRAAPIURL\")\n",
    "            , hydraAPIHost = os.getenv(\"HYDRAAPIHOST\")\n",
    "            , rapidAPIKey = os.getenv(\"RAPIDAPI\")\n",
    "            , imgURL = prplNode.display_url\n",
    "        )\n",
    "        time.sleep(1)\n",
    "            \n",
    "        response = requests.get(_shortUrl)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            pasta = f\"results/{queryHashTag}\"\n",
    "            if not os.path.exists(pasta):\n",
    "                os.makedirs(pasta)\n",
    "                os.makedirs(f\"{pasta}/images\")\n",
    "                os.makedirs(f\"{pasta}/data\")\n",
    "                \n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            img.save(f\"{pasta}/images/{prplNode.owner['id']}-{prplNode.id}.jpg\")\n",
    "        else:\n",
    "            print(\"Falha ao baixar a imagem. Status code:\", response.status_code)\n",
    "            \n",
    "        _dctPrpl = {\n",
    "            \"typename\": prplNode.typename\n",
    "            ,\"id\": prplNode.id\n",
    "            ,\"text\": fluffyText.text\n",
    "            ,\"ownerid\": prplNode.owner['id']\n",
    "            ,\"localurl\": f\"{pasta}/images/{prplNode.owner['id']}-{prplNode.id}.jpg\"\n",
    "            ,\"originalurl\": _shortUrl\n",
    "            ,\"imgClass\": imgClass\n",
    "            ,\"objDtct\": objDtct\n",
    "        }\n",
    "        \n",
    "        lstPrplNode.append(_dctPrpl)\n",
    "        \n",
    "        \n",
    "    # break\n",
    "    if i > 4:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "    \n",
    "dictResult['records'] = lstPrplNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pasta}/data/{queryHashTag}-{timestampNow}.json', 'w') as f:\n",
    "    f.write(json.dumps(dictResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "url = \"https://scontent-lga3-2.cdninstagram.com/v/t51.2885-15/393463999_844386093735145_8392362185252247702_n.jpg?stp=dst-jpg_e35_s1080x1080&_nc_ht=scontent-lga3-2.cdninstagram.com&_nc_cat=101&_nc_ohc=JDTYr_f63RMAX8ZBWrr&edm=AA0rjkIBAAAA&ccb=7-5&oh=00_AfD_4JLuIkYIAITHGpS9V2hToiNhlF7G7XKgajOgYV14bw&oe=65382FA0&_nc_sid=49ed71\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img.save(\"imagem_salva.jpg\")\n",
    "    print(\"Imagem salva com sucesso!\")\n",
    "else:\n",
    "    print(\"Falha ao baixar a imagem. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Defina o caminho para o diretório do conjunto de dados Caltech-256\n",
    "dataset_dir = 'caltech-256'\n",
    "\n",
    "# Listar as classes disponíveis no conjunto de dados\n",
    "classes = os.listdir(dataset_dir)\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Crie listas vazias para armazenar imagens e rótulos\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Carregue imagens e rótulos\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "        if image_path.split(\".\")[-1] != 'jpg':\n",
    "            continue\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, (200, 200))  # Redimensione para o tamanho esperado pelo modelo\n",
    "        images.append(img)\n",
    "        labels.append(classes.index(class_name))\n",
    "\n",
    "# Converta as listas em matrizes numpy\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pré-processamento das imagens (normalização, divisão por 255, etc.)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Definir o modelo\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Avaliar o modelo\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificar uma imagem de entrada\n",
    "# Substitua 'caminho_para_sua_imagem.jpg' pelo caminho para a sua imagem\n",
    "input_image_path = 'imagem_salva.jpg'\n",
    "img = cv2.imread(input_image_path)\n",
    "img = cv2.resize(img, (200, 200))  # Redimensione para o tamanho esperado pelo modelo\n",
    "img = img / 255.0  # Pré-processamento\n",
    "\n",
    "# Faça a previsão\n",
    "img = np.expand_dims(img, axis=0)\n",
    "predictions = model.predict(img)\n",
    "\n",
    "# Obtenha a classe prevista\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Mapeie o índice da classe para o rótulo real\n",
    "predicted_label = classes[predicted_class]\n",
    "\n",
    "print(f'Classe prevista para a imagem: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
